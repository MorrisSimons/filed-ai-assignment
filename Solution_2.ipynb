{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6271ebfe",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "\n",
    "**Do** some test what data can we get with tools like fitz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d97334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "\n",
    "def extract_detailed_font_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results = []\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"dict\")\n",
    "        import json\n",
    "\n",
    "        # Save the blocks dict for each page to a separate JSON file for inspection,\n",
    "        # but remove any non-JSON-serializable objects (like bytes) before dumping.\n",
    "        def remove_bytes(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: remove_bytes(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [remove_bytes(i) for i in obj]\n",
    "            elif isinstance(obj, bytes):\n",
    "                return obj.decode(errors=\"replace\")\n",
    "            else:\n",
    "                return obj\n",
    "\n",
    "        cleaned_blocks = remove_bytes(blocks)\n",
    "        import os\n",
    "        pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        output_dir = f\"blocks_output/{pdf_filename}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        with open(f\"{output_dir}/page_{page_num+1}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(cleaned_blocks, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        for block in blocks[\"blocks\"]:\n",
    "            if \"lines\" in block:\n",
    "                #print(block[\"lines\"])          #<--- Ucomment this to see output\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        #print(span)\n",
    "                        pass\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "detailed_data = []\n",
    "samples_dir = \"samples\"\n",
    "for filename in os.listdir(samples_dir):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(samples_dir, filename)\n",
    "        detailed_data.extend(extract_detailed_font_text(pdf_path))\n",
    "\n",
    "for item in detailed_data:\n",
    "    print(f\"Text: {item['text']}\")\n",
    "    print(f\"Font: {item['font_name']} (Size: {item['font_size']})\")\n",
    "    print(f\"Bold: {item['is_bold']}, Italic: {item['is_italic']}\")\n",
    "    print(f\"Page: {item['page']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627709a",
   "metadata": {},
   "source": [
    "## output\n",
    " The text is structed in a way where you can extract \n",
    "- blocks -> a blocks is a group of lines\n",
    "- lines -> a line is a group of spans\n",
    "- spans -> a span is a group of text\n",
    "- text -> the text of the span\n",
    "\n",
    "\n",
    "\n",
    "so we will probably mine the lines and get font size and font name and then we can use that to classify the document and color of the text.\n",
    "\n",
    "\n",
    "I also added a save function for all the pages in blocks_output so we can see all the data there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59fdfa",
   "metadata": {},
   "source": [
    "## TODO: Lets look at the text data to see if its all there and if i can learn anything from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2692580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: f1098\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: f1099int\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: f1099div\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: handwritten\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: idcard\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: fw2\n",
      "\n",
      "--- page_2.json ---\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: f1099div-2031\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: Morris_Simons_CV_EN \n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "Processing: f1040--2022\n",
      "\n",
      "--- page_2.json ---\n",
      "\n",
      "--- page_1.json ---\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "f1098: 105 text parts\n",
      "f1099int: 105 text parts\n",
      "f1099div: 118 text parts\n",
      "handwritten: 0 text parts\n",
      "idcard: 0 text parts\n",
      "fw2: 221 text parts\n",
      "f1099div-2031: 119 text parts\n",
      "Morris_Simons_CV_EN : 0 text parts\n",
      "f1040--2022: 426 text parts\n",
      "\n",
      "Total text parts across all documents: 1094\n",
      "\n",
      "All filtered text saved to: all_extracted_text_filtered.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to extract all text from JSON files in the blocks_output directory.\n",
    "Filters out dots (\".\") and empty text entries.\n",
    "\"\"\"#\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def extract_text_from_json(file_path):\n",
    "    \"\"\"Extract all text from a single JSON file, filtering out dots and empty text.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        all_text = []\n",
    "        \n",
    "        # Check if the file has the expected structure\n",
    "        if 'blocks' in data:\n",
    "            for block in data['blocks']:\n",
    "                if 'lines' in block:\n",
    "                    for line in block['lines']:\n",
    "                        if 'spans' in line:\n",
    "                            for span in line['spans']:\n",
    "                                if 'text' in span:\n",
    "                                    text = span['text'].strip()\n",
    "                                    # Filter out dots, empty text, and whitespace-only text\n",
    "                                    if text and text != \".\" and text != \"\" and not text.isspace():\n",
    "                                        all_text.append(text)\n",
    "        \n",
    "        return all_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process all JSON files in blocks_output directory.\"\"\"\n",
    "    blocks_dir = Path(\"blocks_output\")\n",
    "    \n",
    "    if not blocks_dir.exists():\n",
    "        print(\"blocks_output directory not found!\")\n",
    "        return\n",
    "    \n",
    "    all_documents_text = {}\n",
    "    \n",
    "    # Process each subdirectory\n",
    "    for subdir in blocks_dir.iterdir():\n",
    "        if subdir.is_dir():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing: {subdir.name}\")\n",
    "\n",
    "            \n",
    "            document_text = []\n",
    "            \n",
    "            # Process each JSON file in the subdirectory\n",
    "            for json_file in subdir.glob(\"*.json\"):\n",
    "                print(f\"\\n--- {json_file.name} ---\")\n",
    "                \n",
    "                text_parts = extract_text_from_json(json_file)\n",
    "                document_text.extend(text_parts)\n",
    "                \n",
    "                # Print text from this file\n",
    "                for i, text in enumerate(text_parts, 1):\n",
    "                    #print(f\"{i:3d}. {text}\") # <--- Ucomment this to see output\n",
    "                    pass\n",
    "            \n",
    "            all_documents_text[subdir.name] = document_text\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    total_text_parts = 0\n",
    "    for doc_name, text_parts in all_documents_text.items():\n",
    "        print(f\"{doc_name}: {len(text_parts)} text parts\")\n",
    "        total_text_parts += len(text_parts)\n",
    "    \n",
    "    print(f\"\\nTotal text parts across all documents: {total_text_parts}\")\n",
    "    \n",
    "    # Save all text to a single file\n",
    "    output_file = \"all_extracted_text_filtered.txt\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for doc_name, text_parts in all_documents_text.items():\n",
    "            f.write(f\"\\n{'='*60}\\n\")\n",
    "            f.write(f\"DOCUMENT: {doc_name}\\n\")\n",
    "            f.write(f\"{'='*60}\\n\\n\")\n",
    "            \n",
    "            for i, text in enumerate(text_parts, 1):\n",
    "                f.write(f\"{i:3d}. {text}\\n\")\n",
    "    \n",
    "    print(f\"\\nAll filtered text saved to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0f6cb",
   "metadata": {},
   "source": [
    "## problem with years:\n",
    "\n",
    "Looking at year i found that for documents like 1098 it uses a 20/ {edit_your_year_here} format while the other documents seems to use a 2024 format but are all empty.\n",
    "This part is a bit tricky because we can use the font and size etc to find it because there are other cols with the same font and size so we might get the wrong year.\n",
    "\n",
    "Here we have a couple of options:\n",
    "- Mabye use OCR on that part of the document.\n",
    "- but the best solution i think is to use the box cordinates of the text and then use that to find the year. (this is something we could add on the other documents awell if we wanted to) Because cordinates tells us where the text is on the page.\n",
    "\n",
    "\n",
    "\n",
    "Looking at the documents w2 and f1040 i think the years are 2024 for w2 and 2022 for 1040.\n",
    "\n",
    "Looking at online documents it seems that From 1040 (2021) - > indicates year 2021 is filed year and it does not based on when the document was modifed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f2232",
   "metadata": {},
   "source": [
    "## ID handling\n",
    "\n",
    "\n",
    "Now to check id i want to use google document ai as this is a library i used before. But if this where to be a comercial project we might want to use azure document ai to scan the id as they have solution to run it on edge. But foe now this is not a on prem solution. But its good and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f4376f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai_v1\n",
    "from typing import Dict, List, Optional\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "location = os.getenv(\"GOOGLE_CLOUD_LOCATION\")\n",
    "processor_id = os.getenv(\"GOOGLE_CLOUD_PROCESSOR_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3a314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID_check(pdf_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Check if the PDF is an ID card using Google Document AI\n",
    "    Returns \"ID Card\" if detected, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set `api_endpoint` if you use a location other than \"us\".\n",
    "        opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "        \n",
    "        # Initialize Document AI client.\n",
    "        client = documentai_v1.DocumentProcessorServiceClient(client_options=opts)\n",
    "        \n",
    "        # Build request\n",
    "        name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "        \n",
    "        # Read the file into memory.\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            file_content = file.read()\n",
    "        \n",
    "        # Load binary data.\n",
    "        raw_document = documentai_v1.RawDocument(\n",
    "            content=file_content,\n",
    "            mime_type=\"application/pdf\",\n",
    "        )\n",
    "        \n",
    "        # Send a request and get the processed document.\n",
    "        request = documentai_v1.ProcessRequest(name=name, raw_document=raw_document)\n",
    "        result = client.process_document(request=request)\n",
    "        document = result.document\n",
    "\n",
    "        # Check if document contains ID-related entities\n",
    "        if document.entities:\n",
    "            for entity in document.entities:\n",
    "                if entity.mention_text:\n",
    "                    mention_text = entity.mention_text.strip().upper()\n",
    "                    if mention_text == \"PASS\":\n",
    "                        print(f\"ID Card detected: {mention_text}\")\n",
    "                        return \"ID Card\"\n",
    "                    elif mention_text == \"NOT_AN_ID\":\n",
    "                        print(f\"Not an ID card: {mention_text}\")\n",
    "                        return None\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ID check: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1cda2",
   "metadata": {},
   "source": [
    "# Handwritten check\n",
    "\n",
    "For this, I used GPT Vision because it is fast, easy to use, and performs well on these types of tasks. However, you can also use specialized models if you prefer.\n",
    "\n",
    "**A kind of quick and dirty solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0933d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handwritten check\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import base64\n",
    "import openai\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd1701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handwritten_check(pdf_path: str) -> str:\n",
    "    \"\"\"Use OpenAI GPT to check if the PDF contains handwritten notes\"\"\"\n",
    "    try:\n",
    "        \n",
    "\n",
    "        # Get OpenAI API key from environment\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            print(\"OpenAI API key not found in environment variables\")\n",
    "            return None\n",
    "            \n",
    "        # Convert PDF to image (first page only for quick check)\n",
    "        images = convert_from_path(pdf_path, first_page=1, last_page=1)\n",
    "        if not images:\n",
    "            return None\n",
    "            \n",
    "        # Convert image to base64\n",
    "        img = images[0]\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format='PNG')\n",
    "        img_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "        \n",
    "        # Create OpenAI client\n",
    "        client = openai.OpenAI(api_key=openai_api_key)\n",
    "        \n",
    "        # Send request to GPT-4 Vision\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Look at this document image. Is this a handwritten notes? Answer with just 'YES' if it's mostly handwritten, or 'NO' if it's something else or typed.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content.strip().upper()\n",
    "        \n",
    "        if result == \"YES\":\n",
    "            print(f\"Handwritten document detected via GPT-4 Vision\")\n",
    "            return \"Handwritten Notes\"\n",
    "        else:\n",
    "            print(f\"Not primarily handwritten (GPT-4 Vision result: {result})\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in handwritten check: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "610abf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: f1098.pdf\n",
      "Looking for year in 1098 form with bbox: [437.46, 98.37, 444.14, 104.38]\n",
      "Using tolerance: 20\n",
      "Found potential year text: '20' at bbox: (421.10400390625, 95.09298706054688, 430.0, 104.42098236083984)\n",
      "Font: HelveticaNeueLTStd-Roman, Size: 8.0\n",
      "Found potential year text: '24' at bbox: (437.46307373046875, 98.37499237060547, 444.1362609863281, 104.37500762939453)\n",
      "Font: Helvetica, Size: 6.000009059906006\n",
      "Matched year: 2024\n",
      "✓ Copied f1098.pdf to classified_pdfs/1098/\n",
      "✓ Year: 2024\n",
      "\n",
      "Processing: handwritten.pdf\n",
      "Not an ID card: NOT_AN_ID\n",
      "Handwritten document detected via GPT-4 Vision\n",
      "✓ Copied handwritten.pdf to classified_pdfs/Handwritten Notes/\n",
      "✓ Year: None\n",
      "\n",
      "Processing: fw2.pdf\n",
      "✓ Copied fw2.pdf to classified_pdfs/W2/\n",
      "✓ Year: 2024\n",
      "\n",
      "Processing: idcard.pdf\n",
      "ID Card detected: PASS\n",
      "✓ Copied idcard.pdf to classified_pdfs/ID Card/\n",
      "✓ Year: None\n",
      "\n",
      "Processing: f1099div-2031.pdf\n",
      "✓ Copied f1099div-2031.pdf to classified_pdfs/1099/\n",
      "✓ Year: 2031\n",
      "\n",
      "Processing: f1040--2022.pdf\n",
      "✓ Copied f1040--2022.pdf to classified_pdfs/1040/\n",
      "✓ Year: 2022\n",
      "\n",
      "Processing: f1099int.pdf\n",
      "✓ Copied f1099int.pdf to classified_pdfs/1099/\n",
      "✓ Year: None\n",
      "\n",
      "Processing: Morris_Simons_CV_EN .pdf\n",
      "Not an ID card: NOT_AN_ID\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 296\u001b[39m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification complete! Check the \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_base_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m directory for results.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[43mclassify_and_copy_pdfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36mclassify_and_copy_pdfs\u001b[39m\u001b[34m(samples_dir, output_base_dir)\u001b[39m\n\u001b[32m    265\u001b[39m     document_type = ID_check(pdf_path) \u001b[38;5;66;03m# Check ID\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m document_type:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     document_type = \u001b[43mhandwritten_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Check Handwritten\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m document_type:\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# Create form-specific directory\u001b[39;00m\n\u001b[32m    273\u001b[39m     form_dir = os.path.join(output_base_dir, document_type)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mhandwritten_check\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     24\u001b[39m client = openai.OpenAI(api_key=openai_api_key)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Send request to GPT-4 Vision\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLook at this document image. Is this a handwritten notes? Answer with just \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mYES\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m if it\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms mostly handwritten, or \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNO\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m if it\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms something else or typed.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     36\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata:image/png;base64,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimg_base64\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     41\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m result = response.choices[\u001b[32m0\u001b[39m].message.content.strip().upper()\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result == \u001b[33m\"\u001b[39m\u001b[33mYES\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1150\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1104\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1147\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1148\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1149\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/filed-ai-assignment/filed-venv-3.13/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional\n",
    "import shutil\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract text content from a PDF using the same method as test_1_get_data.py\n",
    "    Returns a list of text spans with their properties and also complete lines\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results = []\n",
    "    lines = []\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"dict\")\n",
    "        \n",
    "        # Clean blocks for JSON serialization\n",
    "        def remove_bytes(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: remove_bytes(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [remove_bytes(i) for i in obj]\n",
    "            elif isinstance(obj, bytes):\n",
    "                return obj.decode(errors=\"replace\")\n",
    "            else:\n",
    "                return obj\n",
    "\n",
    "        \n",
    "        # Extract text spans and complete lines\n",
    "        for block in blocks[\"blocks\"]:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    line_text = \"\"\n",
    "                    line_spans = []\n",
    "                    \n",
    "                    for span in line[\"spans\"]:\n",
    "                        text = span[\"text\"].strip()\n",
    "                        if text:\n",
    "                            span_info = {\n",
    "                                \"text\": text,\n",
    "                                \"font_name\": span[\"font\"],\n",
    "                                \"font_size\": span[\"size\"],\n",
    "                                \"font_color\": span[\"color\"],\n",
    "                                \"bbox\": span.get(\"bbox\", None),\n",
    "                                \"page\": page_num + 1\n",
    "                            }\n",
    "                            results.append(span_info)\n",
    "                            line_spans.append(span_info)\n",
    "                            line_text += text + \" \"\n",
    "                    \n",
    "                    if line_text.strip():\n",
    "                        lines.append({\n",
    "                            \"text\": line_text.strip(),\n",
    "                            \"spans\": line_spans,\n",
    "                            \"page\": page_num + 1\n",
    "                        })\n",
    "    \n",
    "    doc.close()\n",
    "    return results, lines\n",
    "\n",
    "def analyze_form_content(text_spans: List[Dict], lines: List[Dict]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Analyze text content to determine form type\n",
    "    Returns the form number if found, None otherwise\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        text = line[\"text\"].strip()\n",
    "        \n",
    "        # Check for various form types with their specific font requirements\n",
    "        if text == \"Form 1098\":\n",
    "            if len(line[\"spans\"]) == 2 and line[\"spans\"][0][\"text\"] == \"Form\" and line[\"spans\"][1][\"text\"] == \"1098\":\n",
    "                form_span, num_span = line[\"spans\"][0], line[\"spans\"][1]\n",
    "                if (abs(form_span[\"font_size\"] - 7.0) <= 2 and form_span[\"font_name\"] == \"HelveticaNeueLTStd-Roman\" and\n",
    "                    abs(num_span[\"font_size\"] - 14.0) <= 2 and num_span[\"font_name\"] == \"HelveticaNeueLTStd-Bd\"):\n",
    "\n",
    "                    # Get year from the document by looking for a span with text \"24\" in the expected box area, font, and size\n",
    "                    year = None\n",
    "                    # The expected box for the year \"24\" is approximately:\n",
    "                    # [437.46307373046875, 98.37499237060547, 444.1362609863281, 104.37500762939453]\n",
    "                    year_bbox = [437.46, 98.37, 444.14, 104.38]\n",
    "                    \n",
    "                    # FIXED: Use a single large tolerance for all coordinates\n",
    "                    tolerance = 20  # Reduced tolerance to avoid matching unrelated text\n",
    "                    \n",
    "                    print(f\"Looking for year in 1098 form with bbox: {year_bbox}\")\n",
    "                    print(f\"Using tolerance: {tolerance}\")\n",
    "                    \n",
    "                    for l in lines:\n",
    "                        for s in l.get(\"spans\", []):\n",
    "                            bbox = s.get(\"bbox\", None)\n",
    "                            # Check if bbox is available and matches the expected area with large tolerance\n",
    "                            if bbox and all(abs(b - e) < tolerance for b, e in zip(bbox, year_bbox)):\n",
    "                                # Debug: Show what we found\n",
    "                                print(f\"Found potential year text: '{s.get('text', '')}' at bbox: {bbox}\")\n",
    "                                print(f\"Font: {s.get('font_name', '')}, Size: {s.get('font_size', 0)}\")\n",
    "                                \n",
    "                                # Now check if the text is a 2-digit year (e.g., \"24\", \"21\", \"22\"), font is Helvetica, and size is about 6\n",
    "                                text_val = s.get(\"text\", \"\")\n",
    "                                if (\n",
    "                                    text_val.isdigit() and len(text_val) == 2\n",
    "                                    and abs(s.get(\"font_size\", 0) - 6.0) < 2  # Increased tolerance from 1 to 2\n",
    "                                    and \"Helvetica\" in s.get(\"font_name\", \"\")  # More flexible font matching\n",
    "                                ):\n",
    "                                    # Add millennium prefix\n",
    "                                    year = \"20\" + text_val\n",
    "                                    print(f\"Matched year: {year}\")\n",
    "                                    break\n",
    "                        if year:\n",
    "                            break\n",
    "\n",
    "                    return \"1098\", year\n",
    "\n",
    "\n",
    "        \n",
    "        elif text in [\"Form 1099-INT\", \"Form 1099-DIV\"]:\n",
    "            if len(line[\"spans\"]) == 2 and line[\"spans\"][0][\"text\"] == \"Form\":\n",
    "                form_span, num_span = line[\"spans\"][0], line[\"spans\"][1]\n",
    "                document_type = num_span[\"text\"]  # \"1099-INT\" or \"1099-DIV\"\n",
    "                \n",
    "                # Common font requirements for 1099 forms\n",
    "                if (\n",
    "                    abs(form_span[\"font_size\"] - 7.0) <= 2\n",
    "                    and form_span[\"font_name\"] == \"HelveticaNeueLTStd-Roman\"\n",
    "                    and abs(num_span[\"font_size\"] - 12.0) <= 2\n",
    "                    and num_span[\"font_name\"] == \"HelveticaNeueLTStd-Bd\"\n",
    "                    and text in [\"Form 1099-INT\", \"Form 1099-DIV\"]\n",
    "                ):\n",
    "\n",
    "                    # Get year from the document - look for year in various formats\n",
    "                    year = None\n",
    "\n",
    "                    # Method 1: Look for 4-digit years in the document\n",
    "                    for l in lines:\n",
    "                        for s in l.get(\"spans\", []):\n",
    "                            text_val = s.get(\"text\", \"\").strip()\n",
    "                            if text_val.isdigit() and len(text_val) == 4 and text_val.startswith(\"20\"):\n",
    "                                year = text_val\n",
    "                                break\n",
    "                        if year:\n",
    "                            break\n",
    "\n",
    "\n",
    "                    return \"1099\", year\n",
    "        \n",
    "        elif text == \"Form W-2\":\n",
    "            if len(line[\"spans\"]) == 2 and line[\"spans\"][0][\"text\"] == \"Form\" and line[\"spans\"][1][\"text\"] == \"W-2\":\n",
    "                form_span, num_span = line[\"spans\"][0], line[\"spans\"][1]\n",
    "                if (abs(form_span[\"font_size\"] - 7.0) <= 2 and form_span[\"font_name\"] == \"HelveticaNeueLTStd-Bd\" and\n",
    "                    abs(num_span[\"font_size\"] - 24.0) <= 2 and num_span[\"font_name\"] == \"HelveticaNeueLTStd-BlkCn\"):\n",
    "\n",
    "                    # Get year from the document\n",
    "                    # Find the year from a span with font size 24.0 and font \"OCRAStd\"\n",
    "                    year = \"\"\n",
    "                    for l in lines:\n",
    "                        for s in l.get(\"spans\", []):\n",
    "                            if (\n",
    "                                abs(s.get(\"font_size\", 0) - 24.0) <= 2\n",
    "                                and s.get(\"font_name\", \"\") == \"OCRAStd\"\n",
    "                                and s.get(\"text\", \"\").isdigit()\n",
    "                                and len(s.get(\"text\", \"\")) == 4\n",
    "                            ):\n",
    "                                year = s[\"text\"]\n",
    "                                break\n",
    "                        if year:\n",
    "                            break\n",
    "\n",
    "                    return \"W2\", year\n",
    "        \n",
    "        elif text.startswith(\"Form 1040\"):\n",
    "            if len(line[\"spans\"]) >= 2 and line[\"spans\"][0][\"text\"] == \"Form\" and line[\"spans\"][1][\"text\"] == \"1040\":\n",
    "                form_span, num_span = line[\"spans\"][0], line[\"spans\"][1]\n",
    "                if (abs(form_span[\"font_size\"] - 6.0) <= 2 and form_span[\"font_name\"] == \"HelveticaNeueLTStd-Roman\" and\n",
    "                    abs(num_span[\"font_size\"] - 9.0) <= 2 and num_span[\"font_name\"] == \"HelveticaNeueLTStd-Bd\"):\n",
    "\n",
    "                    # Get year from the document - look for year in various formats\n",
    "                    year = None\n",
    "                    \n",
    "                    # Method 1: Look for year in the form title (e.g., \"Form 1040 (2022)\")\n",
    "                    line_text = line[\"text\"]\n",
    "                    if \"(\" in line_text and \")\" in line_text:\n",
    "                        # Extract year from parentheses\n",
    "                        start = line_text.find(\"(\") + 1\n",
    "                        end = line_text.find(\")\")\n",
    "                        if start < end:\n",
    "                            year_text = line_text[start:end].strip()\n",
    "                            if year_text.isdigit() and len(year_text) == 4 and year_text.startswith(\"20\"):\n",
    "                                year = year_text\n",
    "                    \n",
    "\n",
    "\n",
    "                    return \"1040\", year\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def ID_check(pdf_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Check if the PDF is an ID card using Google Document AI\n",
    "    Returns \"ID Card\" if detected, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set `api_endpoint` if you use a location other than \"us\".\n",
    "        opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "        \n",
    "        # Initialize Document AI client.\n",
    "        client = documentai_v1.DocumentProcessorServiceClient(client_options=opts)\n",
    "        \n",
    "        # Build request\n",
    "        name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "        \n",
    "        # Read the file into memory.\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            file_content = file.read()\n",
    "        \n",
    "        # Load binary data.\n",
    "        raw_document = documentai_v1.RawDocument(\n",
    "            content=file_content,\n",
    "            mime_type=\"application/pdf\",\n",
    "        )\n",
    "        \n",
    "        # Send a request and get the processed document.\n",
    "        request = documentai_v1.ProcessRequest(name=name, raw_document=raw_document)\n",
    "        result = client.process_document(request=request)\n",
    "        document = result.document\n",
    "\n",
    "        # Check if document contains ID-related entities\n",
    "        if document.entities:\n",
    "            for entity in document.entities:\n",
    "                if entity.mention_text:\n",
    "                    mention_text = entity.mention_text.strip().upper()\n",
    "                    if mention_text == \"PASS\":\n",
    "                        print(f\"ID Card detected: {mention_text}\")\n",
    "                        return \"ID Card\"\n",
    "                    elif mention_text == \"NOT_AN_ID\":\n",
    "                        print(f\"Not an ID card: {mention_text}\")\n",
    "                        return None\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ID check: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def classify_and_copy_pdfs(samples_dir: str = \"samples\", output_base_dir: str = \"classified_pdfs\"):\n",
    "    \"\"\"\n",
    "    Main function to classify PDFs and copy them to appropriate folders\n",
    "    \"\"\"\n",
    "    # Create output base directory\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each PDF in the samples directory\n",
    "    for filename in os.listdir(samples_dir):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(samples_dir, filename)\n",
    "            print(f\"\\nProcessing: {filename}\")\n",
    "            \n",
    "            try:\n",
    "                # Extract text content\n",
    "                text_spans, lines = extract_text_from_pdf(pdf_path)\n",
    "                \n",
    "                # Analyze content to determine form type\n",
    "                document_type, year = analyze_form_content(text_spans, lines)\n",
    "                \n",
    "                if not document_type:\n",
    "                    document_type = ID_check(pdf_path) # Check ID\n",
    "\n",
    "                if not document_type:\n",
    "                    document_type = handwritten_check(pdf_path) # Check Handwritten\n",
    "\n",
    "\n",
    "                if document_type:\n",
    "                    # Create form-specific directory\n",
    "                    form_dir = os.path.join(output_base_dir, document_type)\n",
    "                    os.makedirs(form_dir, exist_ok=True)\n",
    "                    \n",
    "                    # Copy PDF to form directory\n",
    "                    destination = os.path.join(form_dir, filename)\n",
    "                    shutil.copy2(pdf_path, destination)\n",
    "                    print(f\"✓ Copied {filename} to {form_dir}/\")\n",
    "                    print(f\"✓ Year: {year}\")\n",
    "                else:\n",
    "                    # If no form type detected, put in \"unknown\" folder\n",
    "                    unknown_dir = os.path.join(output_base_dir, \"Other\")\n",
    "                    os.makedirs(unknown_dir, exist_ok=True)\n",
    "                    destination = os.path.join(unknown_dir, filename)\n",
    "                    shutil.copy2(pdf_path, destination)\n",
    "                    print(f\"? No form type detected for {filename}, copied to Other/\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nClassification complete! Check the '{output_base_dir}' directory for results.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classify_and_copy_pdfs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filed-venv-3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
